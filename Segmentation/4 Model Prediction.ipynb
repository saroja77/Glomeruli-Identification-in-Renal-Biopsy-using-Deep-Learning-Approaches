{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH_jYQIEZQ_G"
      },
      "outputs": [],
      "source": [
        "!pip install -q catalyst==20.12\n",
        "!pip install -q pytorch-toolbelt==0.4.2\n",
        "!pip install -q torch-optimizer==0.1.0\n",
        "!pip install -q segmentation-models-pytorch==0.1.3\n",
        "!pip install -q ttach==0.0.3\n",
        "!pip install -q albumentations==0.5.2\n",
        "!pip install timm==0.3.2\n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import warnings\n",
        "\n",
        "from catalyst.contrib.nn import OneCycleLRWithWarmup\n",
        "from torch.optim.lr_scheduler import (\n",
        "    ExponentialLR,\n",
        "    CyclicLR,\n",
        "    MultiStepLR,\n",
        "    CosineAnnealingLR,\n",
        "    CosineAnnealingWarmRestarts,\n",
        "    ReduceLROnPlateau\n",
        ")\n",
        "from pytorch_toolbelt.losses import *\n",
        "from pytorch_toolbelt.utils import image_to_tensor\n",
        "from pytorch_toolbelt.utils.random import set_manual_seed\n",
        "from torch.nn import KLDivLoss\n",
        "from catalyst import utils\n",
        "from catalyst.contrib.nn import OneCycleLRWithWarmup\n",
        "from catalyst import dl\n",
        "from catalyst.contrib.utils.cv import image as cata_image\n",
        "from catalyst.contrib.callbacks.wandb_logger import WandbLogger\n",
        "from catalyst.dl import (\n",
        "    SupervisedRunner,\n",
        "    CriterionCallback,\n",
        "    EarlyStoppingCallback,\n",
        "    SchedulerCallback,\n",
        "    MetricAggregationCallback,\n",
        "    IouCallback,\n",
        "    DiceCallback,\n",
        "    InferCallback, CheckpointCallback\n",
        ")\n",
        "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
        "from pathlib import Path\n",
        "from tqdm .auto import tqdm\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "from typing import List,  Optional, Dict\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "UWYQABSDJ22S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAIN_PATH = Path('/content/drive/MyDrive/hubmap256x256')\n",
        "IMG_PATHS = MAIN_PATH / 'train'\n",
        "MASK_PATHS = MAIN_PATH / 'masks'\n",
        "LABEL = '/content/drive/MyDrive/kidneysegmentation/train.csv'\n",
        "TEST_IMG_PATHS = MAIN_PATH / 'test'\n",
        "TEST_MASK = MAIN_PATH / 'test_masks'"
      ],
      "metadata": {
        "id": "jeHJYPkXJTAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseConfig:\n",
        "    __basedir__ = MAIN_PATH\n",
        "    train_img_path = IMG_PATHS\n",
        "    train_mask_path = MASK_PATHS\n",
        "\n",
        "    #Data config\n",
        "    augmentation = 'medium' #options: normal, easy, medium, advanced\n",
        "    scale_size = 256\n",
        "\n",
        "    #Train config\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "    val_batch_size = 32\n",
        "    learning_rate = 1e-5\n",
        "    learning_rate_decode = 1e-3\n",
        "    weight_decay = 2.5e-5\n",
        "    is_fp16 = True\n",
        "\n",
        "    #Model config\n",
        "    model_name = None\n",
        "    model_params = None\n",
        "\n",
        "    #Metric config\n",
        "    metric = \"dice\"\n",
        "    mode = \"max\"\n",
        "\n",
        "    #Optimize config\n",
        "    criterion = {\"bce\": 0.8, 'log_dice': 0.2}\n",
        "    pos_weights = [200]\n",
        "    optimizer = \"madgrad\"\n",
        "    scheduler = \"simple\"\n",
        "\n",
        "    resume_path = None #Resume training\n",
        "\n",
        "    @classmethod\n",
        "    def get_all_attributes(cls):\n",
        "        d = {}\n",
        "        attributes = dict(cls.__dict__)\n",
        "\n",
        "        for k, v in attributes.items():\n",
        "            if not k.startswith('__') and k != 'get_all_attributes':\n",
        "                d[k] = v\n",
        "\n",
        "        return d"
      ],
      "metadata": {
        "id": "ZcPtewkkLdIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = BaseConfig.get_all_attributes()"
      ],
      "metadata": {
        "id": "ex4QsZVsLgWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HUBMAPSegmentation(Dataset):\n",
        "    def __init__(self, images: List[Path], masks: List[Path] = None, transform=None, preprocessing_fn=None):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.transform = transform\n",
        "        self.preprocessing_fn = preprocessing_fn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index: int) -> dict:\n",
        "        image_path = self.images[index]\n",
        "\n",
        "        result = OrderedDict()\n",
        "        image = cata_image.imread(image_path)\n",
        "        result['image'] = image\n",
        "\n",
        "        if self.masks is not None:\n",
        "            mask = Image.open(self.masks[index]).convert('L')\n",
        "            mask = mask.point(lambda x: 255 if x > 0 else 0, '1')\n",
        "            mask = np.asarray(mask).astype(np.uint8)\n",
        "            result['mask'] = mask\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(**result)\n",
        "            image = transformed['image']\n",
        "            if self.masks is not None:\n",
        "                mask = transformed['mask']\n",
        "                mask = image_to_tensor(mask, dummy_channels_dim=True).float()\n",
        "                result['mask'] = mask\n",
        "\n",
        "        if self.preprocessing_fn is not None:\n",
        "            image = self.preprocessing_fn(image = image)['image']\n",
        "\n",
        "        image = image_to_tensor(image).float()\n",
        "        result['image'] = image\n",
        "        result['filename'] = image_path.name\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "fTDHtn8DLqvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(\n",
        "    images: List[Path],\n",
        "    random_state: int,\n",
        "    valid_size: float = 0.2,\n",
        "    batch_size: int = 4,\n",
        "    val_batch_size: int = 8,\n",
        "    num_workers: int = 4,\n",
        "    train_transforms_fn=None,\n",
        "    valid_transforms_fn=None,\n",
        "    preprocessing_fn=None,\n",
        "    masks: List[Path] = None,\n",
        "):\n",
        "    indices = np.arange(len(images))\n",
        "\n",
        "    train_indices, valid_indices = train_test_split(\n",
        "        indices, test_size=valid_size, random_state=random_state, shuffle=True)\n",
        "\n",
        "    np_images = np.array(images)\n",
        "    train_images = np_images[train_indices].tolist()\n",
        "    val_images = np_images[valid_indices].tolist()\n",
        "    np_masks = np.array(masks)\n",
        "    train_masks = np_masks[train_indices].tolist()\n",
        "    val_masks = np_masks[valid_indices].tolist()\n",
        "\n",
        "\n",
        "    train_dataset = HUBMAPSegmentation(\n",
        "        sorted(train_images),\n",
        "        masks=sorted(train_masks),\n",
        "        transform=train_transforms_fn,\n",
        "        preprocessing_fn=preprocessing_fn,\n",
        "    )\n",
        "\n",
        "    valid_dataset = HUBMAPSegmentation(\n",
        "        sorted(val_images),\n",
        "        masks=sorted(val_masks),\n",
        "        transform=valid_transforms_fn,\n",
        "        preprocessing_fn=preprocessing_fn,\n",
        "    )\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=val_batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    loaders = OrderedDict()\n",
        "    loaders['train'] = train_loader\n",
        "    loaders['valid'] = valid_loader\n",
        "    loaders['valid_dataset'] = valid_dataset\n",
        "    # loaders['test'] = test_loader\n",
        "\n",
        "    return loaders"
      ],
      "metadata": {
        "id": "4n_nL-31JUH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseTransform(object):\n",
        "    def __init__(self, image_size: int = 1024, preprocessing_fn=None):\n",
        "        self.image_size = image_size\n",
        "        self.preprocessing_fn = preprocessing_fn\n",
        "\n",
        "    def pre_transform(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def hard_transform(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def resize_transforms(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _get_compose(self, transform):\n",
        "        result = A.Compose([\n",
        "            item for sublist in transform for item in sublist\n",
        "        ])\n",
        "        return result\n",
        "\n",
        "    def train_transform(self):\n",
        "        return self._get_compose([\n",
        "            self.resize_transforms(),\n",
        "            self.hard_transform()\n",
        "        ])\n",
        "\n",
        "    def validation_transform(self):\n",
        "        return self._get_compose([\n",
        "            self.pre_transform()\n",
        "        ])\n",
        "\n",
        "    def test_transform(self):\n",
        "        return self.validation_transform()\n",
        "\n",
        "    def get_preprocessing(self):\n",
        "        return A.Compose([\n",
        "            A.Lambda(image=self.preprocessing_fn)\n",
        "        ])\n",
        "\n",
        "class NormalTransform(BaseTransform):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(NormalTransform, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def hard_transform(self):\n",
        "        return [\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomRotate90(p=0.7),\n",
        "        ]\n",
        "\n",
        "    def resize_transforms(self):\n",
        "        return [\n",
        "            A.LongestMaxSize(self.image_size),\n",
        "            A.PadIfNeeded(min_height=self.image_size, min_width=self.image_size,\n",
        "                          border_mode=cv2.BORDER_CONSTANT, value=0)\n",
        "        ]\n",
        "\n",
        "    def pre_transform(self):\n",
        "        return self.resize_transforms()\n",
        "\n",
        "class MediumTransform(NormalTransform):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MediumTransform, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def hard_transform(self):\n",
        "        return [\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomRotate90(p=0.7),\n",
        "            A.OneOf([\n",
        "                A.ElasticTransform(alpha=120, sigma=120 * 0.05,\n",
        "                                   alpha_affine=120 * 0.03, p=0.5),\n",
        "                A.GridDistortion(p=0.5),\n",
        "                A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=0.5)\n",
        "            ], p=0.5),\n",
        "            A.CLAHE(p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            A.RandomGamma(p=0.5)\n",
        "        ]\n",
        "\n",
        "\n",
        "def get_transform(name):\n",
        "    if name == 'normal':\n",
        "        return NormalTransform\n",
        "    if name == 'easy':\n",
        "        return EasyTransform\n",
        "    if name == 'medium':\n",
        "        return MediumTransform\n",
        "    if name == 'advanced':\n",
        "        return AdvancedTransform"
      ],
      "metadata": {
        "id": "MluwuER4L1py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = get_transform('medium')(train_config['scale_size'])\n",
        "test_transform = normal.test_transform()\n",
        "test_images = sorted(TEST_IMG_PATHS.glob('*.*'))\n",
        "test_masks = sorted(TEST_MASK.glob('*.*'))\n",
        "indices = np.arange(len(test_images))\n"
      ],
      "metadata": {
        "id": "FVlo-4TRLOqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = HUBMAPSegmentation(\n",
        "        sorted(test_images),\n",
        "        transform=test_transform\n",
        "    )"
      ],
      "metadata": {
        "id": "vTdcdpZwMI1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        num_workers=2,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )"
      ],
      "metadata": {
        "id": "bm9vzGbNMKzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(params, model_name):\n",
        "\n",
        "    # Model return logit values\n",
        "    #if ensemble\n",
        "    #if model_name == \"model_ensemble\":\n",
        "\n",
        "    model = getattr(smp, model_name)(\n",
        "        **params\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "7_nzccfKMPlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_everything(exp_name):\n",
        "    print(\"===> Get model\")\n",
        "    model = get_model(\n",
        "        train_config['model_params'],\n",
        "        train_config['model_name']\n",
        "    )\n",
        "\n",
        "    print(\"===> Get transformation\")\n",
        "    #Define transform (augemntation)\n",
        "    Transform = get_transform(train_config['augmentation'])\n",
        "    transforms = Transform(\n",
        "        train_config['scale_size'],\n",
        "        preprocessing_fn=preprocessing_fn\n",
        "    )\n",
        "\n",
        "    train_transform = transforms.train_transform()\n",
        "    val_transform = transforms.validation_transform()\n",
        "    preprocessing = transforms.get_preprocessing()\n",
        "\n",
        "    print(\"===> Get data loader\")\n",
        "    loader = get_loader(\n",
        "        images = sorted(train_config['train_img_path'].glob('*.*')),\n",
        "        masks = sorted(train_config['train_mask_path'].glob('*.*')),\n",
        "        random_state = SEED,\n",
        "        valid_size = 0.2,\n",
        "        batch_size = train_config['batch_size'],\n",
        "        val_batch_size = train_config['val_batch_size'],\n",
        "        num_workers = 2,\n",
        "        train_transforms_fn=train_transform,\n",
        "        valid_transforms_fn=val_transform,\n",
        "        preprocessing_fn=preprocessing\n",
        "    )\n",
        "\n",
        "    print(\"===> Get optimizer\")\n",
        "    param_group = []\n",
        "    if hasattr(model, 'encoder'):\n",
        "        encoder_params = filter(lambda p: p.requires_grad, model.encoder.parameters())\n",
        "        param_group += [{'params': encoder_params, 'lr': train_config['learning_rate']}]\n",
        "    if hasattr(model, 'decoder'):\n",
        "        decoder_params = filter(lambda p: p.requires_grad, model.decoder.parameters())\n",
        "        param_group += [{'params': decoder_params}]\n",
        "    if hasattr(model, 'segmentation_head'):\n",
        "        head_params = filter(lambda p: p.requires_grad, model.segmentation_head.parameters())\n",
        "        param_group += [{'params': head_params}]\n",
        "    if len(param_group) == 0:\n",
        "        param_group = list(model.parameters())\n",
        "\n",
        "    total = int(sum(p.numel() for p in model.parameters()))\n",
        "    trainable = int(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "    count_parameters = {\"total\": total, \"trainable\": trainable}\n",
        "\n",
        "    print(\n",
        "        f'[INFO] total and trainable parameters in the model {count_parameters}'\n",
        "    )\n",
        "\n",
        "    #Set optimizer\n",
        "    optimizer = get_optimizer(\n",
        "        train_config['optimizer'], param_group, train_config['learning_rate_decode'], train_config['weight_decay'])\n",
        "\n",
        "    print(\"===> Get shceduler\")\n",
        "    scheduler = get_scheduler(\n",
        "        train_config['scheduler'], optimizer, train_config['learning_rate'], train_config['num_epochs'],\n",
        "        batches_in_epoch=len(loader['train']), mode=train_config['mode']\n",
        "    )\n",
        "\n",
        "    print(\"===> Get loss\")\n",
        "    criterion = {}\n",
        "    for loss_name in train_config['criterion']:\n",
        "        if loss_name == 'wbce':\n",
        "            pos_weights = torch.tensor(train_config['pos_weights'], device=utils.get_device())\n",
        "            loss_fn = WeightedBCEWithLogits(pos_weights=pos_weights)\n",
        "        else:\n",
        "            loss_fn = get_loss(loss_name)\n",
        "        criterion[loss_name] = loss_fn\n",
        "\n",
        "    print(\"===> Get callbacks\")\n",
        "    #Define callbacks\n",
        "    callbacks = []\n",
        "    losses = []\n",
        "    for loss_name, loss_weight in train_config['criterion'].items():\n",
        "        criterion_callback = CriterionCallback(\n",
        "            input_key=\"mask\",\n",
        "            output_key=\"logits\",\n",
        "            criterion_key=loss_name,\n",
        "            prefix=\"loss_\"+loss_name,\n",
        "            multiplier=float(loss_weight)\n",
        "        )\n",
        "\n",
        "        callbacks.append(criterion_callback)\n",
        "        losses.append(criterion_callback.prefix)\n",
        "\n",
        "    callbacks += [MetricAggregationCallback(\n",
        "        prefix=\"loss\",\n",
        "        mode=\"sum\",\n",
        "        metrics=losses\n",
        "    )]\n",
        "\n",
        "    if isinstance(scheduler, (CyclicLR, OneCycleLRWithWarmup)):\n",
        "        callbacks += [SchedulerCallback(mode=\"batch\")]\n",
        "    elif isinstance(scheduler, (ReduceLROnPlateau)):\n",
        "        callbacks += [SchedulerCallback(reduced_metric=train_config['metric'])]\n",
        "\n",
        "    early_stopping = EarlyStoppingCallback(\n",
        "        patience=10, metric=train_config['metric'], minimize=False)\n",
        "\n",
        "    iou_scores = IouCallback(\n",
        "        input_key=\"mask\",\n",
        "        activation=\"Sigmoid\",\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    dice_scores = DiceCallback(\n",
        "        input_key=\"mask\",\n",
        "        activation=\"Sigmoid\",\n",
        "        threshold=0.5\n",
        "    )\n",
        "\n",
        "    prefix = exp_name\n",
        "    log_dir = os.path.join(\"/content/drive/MyDrive/training\", prefix)\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "\n",
        "    callbacks += [early_stopping,\n",
        "                  iou_scores, dice_scores]\n",
        "\n",
        "    print(\"===> Saving config setting\")\n",
        "    #Save config as JSON format\n",
        "    with open(os.path.join(log_dir, 'config.json'), 'w') as f:\n",
        "        save_config = train_config.copy()\n",
        "        save_config['train_img_path'] = str(save_config['train_img_path'])\n",
        "        save_config['train_mask_path'] = str(save_config['train_mask_path'])\n",
        "        json.dump(save_config, f)\n",
        "\n",
        "    print(\"===> Done\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'loader': loader,\n",
        "        'optimizer': optimizer,\n",
        "        'criterion': criterion,\n",
        "        'callbacks': callbacks,\n",
        "        'scheduler': scheduler,\n",
        "        'log_dir': log_dir\n",
        "    }"
      ],
      "metadata": {
        "id": "HJ3Dj-MWMX0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wGaCbpH5Mn_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}